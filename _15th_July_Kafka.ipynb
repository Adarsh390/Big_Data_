{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setting up a Kafka Producer:\n",
    "#    a) Write a Python program to create a Kafka producer.\n",
    "#    b) Configure the producer to connect to a Kafka cluster.\n",
    "#    c) Implement logic to send messages to a Kafka topic.\n",
    "#Sol:\n",
    "from kafka import KafkaProducer\n",
    "\n",
    "# Set up Kafka producer configuration\n",
    "bootstrap_servers = 'your_kafka_server:9092'  # Replace with your Kafka server address\n",
    "topic = 'your_topic'  # Replace with your desired Kafka topic\n",
    "\n",
    "# Create Kafka producer\n",
    "producer = KafkaProducer(bootstrap_servers=bootstrap_servers)\n",
    "\n",
    "# Function to send messages to Kafka topic\n",
    "def send_message(message):\n",
    "    producer.send(topic, message.encode('utf-8'))\n",
    "    producer.flush()  # Optional: To ensure the message is sent immediately\n",
    "\n",
    "# Example usage\n",
    "message = 'Hello, Kafka!'\n",
    "send_message(message)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Setting up a Kafka Consumer:\n",
    "#    a) Write a Python program to create a Kafka consumer.\n",
    "#    b) Configure the consumer to connect to a Kafka cluster.\n",
    "#    c) Implement logic to consume messages from a Kafka topic.\n",
    "#Sol:\n",
    "from confluent_kafka import Consumer, KafkaError\n",
    "\n",
    "# Kafka cluster configuration\n",
    "bootstrap_servers = 'localhost:9092'\n",
    "topic = 'your_topic_name'\n",
    "group_id = 'your_consumer_group_id'\n",
    "\n",
    "# Create consumer configuration\n",
    "consumer_config = {\n",
    "    'bootstrap.servers': bootstrap_servers,\n",
    "    'group.id': group_id,\n",
    "    'auto.offset.reset': 'earliest'  # Set to 'latest' if you want to consume only new messages\n",
    "}\n",
    "\n",
    "# Create Kafka consumer instance\n",
    "consumer = Consumer(consumer_config)\n",
    "\n",
    "# Subscribe to the Kafka topic\n",
    "consumer.subscribe([topic])\n",
    "\n",
    "# Start consuming messages\n",
    "try:\n",
    "    while True:\n",
    "        msg = consumer.poll(1.0)  # Wait for 1 second for new messages\n",
    "\n",
    "        if msg is None:\n",
    "            continue\n",
    "        elif msg.error():\n",
    "            if msg.error().code() == KafkaError._PARTITION_EOF:\n",
    "                # End of partition, continue polling\n",
    "                continue\n",
    "            else:\n",
    "                # Handle other errors\n",
    "                print(f'Error: {msg.error().str()}')\n",
    "                continue\n",
    "\n",
    "        # Process the received message\n",
    "        print(f'Received message: {msg.value().decode(\"utf-8\")}')\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "# Close the consumer\n",
    "consumer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Creating and Managing Kafka Topics:\n",
    "# a) Write a Python program to create a new Kafka topic.\n",
    "#Sol:\n",
    "from kafka.admin import KafkaAdminClient, NewTopic\n",
    "\n",
    "def create_topic(bootstrap_servers, topic_name, partitions=1, replication_factor=1):\n",
    "    admin_client = KafkaAdminClient(bootstrap_servers=bootstrap_servers)\n",
    "    topic = NewTopic(name=topic_name, num_partitions=partitions, replication_factor=replication_factor)\n",
    "    admin_client.create_topics([topic])\n",
    "    print(f\"Topic '{topic_name}' created successfully!\")\n",
    "\n",
    "# Example usage\n",
    "bootstrap_servers = 'localhost:9092'  # Replace with your Kafka broker addresses\n",
    "topic_name = 'my_topic'\n",
    "create_topic(bootstrap_servers, topic_name)\n",
    "\n",
    "# b) Implement functionality to list existing topics.\n",
    "#Sol:\n",
    "from kafka import KafkaAdminClient\n",
    "\n",
    "def list_topics(bootstrap_servers):\n",
    "    admin_client = KafkaAdminClient(bootstrap_servers=bootstrap_servers)\n",
    "    topics = admin_client.list_topics()\n",
    "    print(\"Existing topics:\")\n",
    "    for topic in topics:\n",
    "        print(topic)\n",
    "\n",
    "# Example usage\n",
    "bootstrap_servers = 'localhost:9092'  # Replace with your Kafka broker addresses\n",
    "list_topics(bootstrap_servers)\n",
    "# c) Develop logic to delete an existing Kafka topic.\n",
    "#Sol:\n",
    "from kafka.admin import KafkaAdminClient\n",
    "\n",
    "def delete_topic(bootstrap_servers, topic_name):\n",
    "    admin_client = KafkaAdminClient(bootstrap_servers=bootstrap_servers)\n",
    "    admin_client.delete_topics([topic_name])\n",
    "    print(f\"Topic '{topic_name}' deleted successfully!\")\n",
    "\n",
    "# Example usage\n",
    "bootstrap_servers = 'localhost:9092'  # Replace with your Kafka broker addresses\n",
    "topic_name = 'my_topic'\n",
    "delete_topic(bootstrap_servers, topic_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Producing and Consuming Messages:\n",
    "#    a) Write a Python program to produce messages to a Kafka topic.\n",
    "# Sol:\n",
    "from kafka import KafkaProducer\n",
    "\n",
    "def produce_messages(bootstrap_servers, topic_name, messages):\n",
    "    producer = KafkaProducer(bootstrap_servers=bootstrap_servers)\n",
    "    for message in messages:\n",
    "        producer.send(topic_name, message.encode('utf-8'))\n",
    "    producer.flush()\n",
    "    print(\"Messages produced successfully!\")\n",
    "\n",
    "# Example usage\n",
    "bootstrap_servers = 'localhost:9092'  # Replace with your Kafka broker addresses\n",
    "topic_name = 'my_topic'\n",
    "messages = ['Hello', 'World']\n",
    "produce_messages(bootstrap_servers, topic_name, messages)\n",
    "\n",
    "# b) Implement logic to consume messages from the same Kafka topic.\n",
    "# c) Test the end-to-end flow of message production and consumption.\n",
    "# Sol:\n",
    "from kafka import KafkaConsumer\n",
    "\n",
    "def consume_messages(bootstrap_servers, topic_name):\n",
    "    consumer = KafkaConsumer(bootstrap_servers=bootstrap_servers, group_id='my_consumer_group')\n",
    "    consumer.subscribe([topic_name])\n",
    "\n",
    "    for message in consumer:\n",
    "        print(f\"Received message: {message.value.decode('utf-8')}\")\n",
    "\n",
    "# Example usage\n",
    "bootstrap_servers = 'localhost:9092'  # Replace with your Kafka broker addresses\n",
    "topic_name = 'my_topic'\n",
    "consume_messages(bootstrap_servers, topic_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Working with Kafka Consumer Groups:\n",
    "#    a) Write a Python program to create a Kafka consumer within a consumer group.\n",
    "#Sol:\n",
    "from confluent_kafka import Consumer, KafkaError\n",
    "\n",
    "def consume_messages():\n",
    "    consumer_config = {\n",
    "        'bootstrap.servers': 'localhost:9092',  # Kafka broker(s) address\n",
    "        'group.id': 'my-consumer-group',  # Consumer group ID\n",
    "        'auto.offset.reset': 'earliest'  # Start consuming from the beginning of the topic\n",
    "    }\n",
    "\n",
    "    consumer = Consumer(consumer_config)\n",
    "    consumer.subscribe(['my-topic'])  # Subscribe to the desired topic(s)\n",
    "\n",
    "    while True:\n",
    "        message = consumer.poll(1.0)  # Poll for new messages, with a timeout of 1 second\n",
    "\n",
    "        if message is None:\n",
    "            continue\n",
    "\n",
    "        if message.error():\n",
    "            if message.error().code() == KafkaError._PARTITION_EOF:\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"Error: {message.error()}\")\n",
    "                break\n",
    "\n",
    "        # Process the consumed message\n",
    "        print(f\"Received message: {message.value().decode('utf-8')}\")\n",
    "\n",
    "    consumer.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    consume_messages()\n",
    "\n",
    "#    b) Implement logic to handle messages consumed by different consumers within the same group.\n",
    "#Sol:\n",
    "from confluent_kafka import Consumer, KafkaError\n",
    "\n",
    "def consume_messages():\n",
    "    consumer_config = {\n",
    "        'bootstrap.servers': 'localhost:9092',  # Kafka broker(s) address\n",
    "        'group.id': 'my-consumer-group',  # Consumer group ID\n",
    "        'auto.offset.reset': 'earliest'  # Start consuming from the beginning of the topic\n",
    "    }\n",
    "\n",
    "    consumer = Consumer(consumer_config)\n",
    "    consumer.subscribe(['my-topic'])  # Subscribe to the desired topic(s)\n",
    "\n",
    "    while True:\n",
    "        message = consumer.poll(1.0)  # Poll for new messages, with a timeout of 1 second\n",
    "\n",
    "        if message is None:\n",
    "            continue\n",
    "\n",
    "        if message.error():\n",
    "            if message.error().code() == KafkaError._PARTITION_EOF:\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"Error: {message.error()}\")\n",
    "                break\n",
    "\n",
    "        # Process the consumed message\n",
    "        process_message(message)\n",
    "\n",
    "    consumer.close()\n",
    "\n",
    "\n",
    "def process_message(message):\n",
    "    # Implement your logic to handle the message here\n",
    "    print(f\"Consumer ID: {message.key().decode('utf-8')}, Message: {message.value().decode('utf-8')}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    consume_messages()\n",
    "\n",
    "#    c) Observe the behavior of consumer group rebalancing when adding or removing consumers.\n",
    "#Sol:\n",
    "# When you add or remove consumers from a Kafka consumer group, the group undergoes rebalancing. Rebalancing involves redistributing the partitions among the active consumers to ensure that each consumer is assigned a fair share of partitions.\n",
    "\n",
    "# To observe the behavior of consumer group rebalancing when adding or removing consumers, you can follow these steps:\n",
    "\n",
    "# 1:Start the initial set of consumers running the consumer program mentioned in part (a).\n",
    "# 2:Observe the partition assignments for each consumer in the group. You can print the assigned partitions using the assignment() method of the consumer object.\n",
    "# 3:Add or remove consumers from the consumer group by starting or stopping additional instances of the consumer program.\n",
    "# 4:Observe the console output of the consumers. You will see that the partition assignments may change as rebalancing occurs.\n",
    "# 5:Monitor the partition assignments periodically to see how they adjust during rebalancing.\n",
    "\n",
    "# By following these steps, you can observe how Kafka handles consumer group rebalancing dynamically based on the number of consumers and the topic's partition configuration.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
